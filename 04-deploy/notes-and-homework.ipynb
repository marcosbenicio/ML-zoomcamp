{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Outline**\n",
    "\n",
    "- [**1. Data preparation**](#1-data-preparation)\n",
    "- [**2. Preparing Virtual Environment with Pipenv**](#2-preparing-virtual-environment-with-pipenv)\n",
    "- [**3. Load Model with Pickle**](#3-load-model-with-pickle)\n",
    "- [**4. Load Model in Web service with Flask**](#4-load-model-in-web-service-with-flask)\n",
    "- [**5. Docker**](#5-docker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Data Preparation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Bank credit scoring dataset from [kaggle](https://www.kaggle.com/datasets/kapturovalexander/bank-credit-scoring/data).\n",
    "\n",
    "We've prepared a dictionary vectorizer and a model.\n",
    "\n",
    "They were trained (roughly) using this code:\n",
    "\n",
    "```python\n",
    "    features = ['job','duration', 'poutcome']\n",
    "    dicts = df[features].to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X = dv.fit_transform(dicts)\n",
    "\n",
    "    model = LogisticRegression().fit(X, y)\n",
    "```\n",
    "And then saved with Pickle. Download them from:\n",
    "\n",
    "* [DictVectorizer](https://github.com/DataTalksClub/machine-learning-zoomcamp/tree/master/cohorts/2023/05-deployment/homework/dv.bin?raw=true)\n",
    "* [LogisticRegression](https://github.com/DataTalksClub/machine-learning-zoomcamp/tree/master/cohorts/2023/05-deployment/homework/model1.bin?raw=true)\n",
    "\n",
    "With `wget`:\n",
    "\n",
    "```bash\n",
    "PREFIX=https://raw.githubusercontent.com/DataTalksClub/machine-learning-zoomcamp/master/cohorts/2023/05-deployment/homework\n",
    "wget $PREFIX/model1.bin\n",
    "wget $PREFIX/dv.bin\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using  `wget`,  we downloaded the two files: the **pre-trained model** (`model1.bin`) and the **vectorized dictionary** (`dv.bin`).\n",
    "\n",
    "`Terminal`\n",
    "\n",
    "------\n",
    "```bash\n",
    "marcos@marcos:~/GitHub/ML_Zoomcamp/05Deploy/Homework$ PREFIX=https://raw.githubusercontent.com/DataTalksClub/machine-learning-zoomcamp/master/cohorts/2023/05-deployment/homework\n",
    "marcos@marcos:~/GitHub/ML_Zoomcamp/05Deploy/Homework$ wget $PREFIX/model1.bin\n",
    "marcos@marcos:~/GitHub/ML_Zoomcamp/05Deploy/Homework$ wget $PREFIX/dv.bin\n",
    "marcos@marcos:~/GitHub/ML_Zoomcamp/05Deploy/Homework$ ls\n",
    "dv.bin  model1.bin  Pipfile  Pipfile.lock\n",
    "```\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job</th>\n",
       "      <th>duration</th>\n",
       "      <th>poutcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unemployed</td>\n",
       "      <td>79</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>services</td>\n",
       "      <td>220</td>\n",
       "      <td>failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>management</td>\n",
       "      <td>185</td>\n",
       "      <td>failure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>management</td>\n",
       "      <td>199</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blue-collar</td>\n",
       "      <td>226</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           job  duration poutcome\n",
       "0   unemployed        79  unknown\n",
       "1     services       220  failure\n",
       "2   management       185  failure\n",
       "3   management       199  unknown\n",
       "4  blue-collar       226  unknown"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset used to train the model\n",
    "df = pd.read_csv(\"data/bank.csv\")\n",
    "features = ['job', 'duration', 'poutcome']\n",
    "df = df[features] \n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Preparing Virtual Environment with Pipenv**\n",
    "\n",
    "Pipenv permits us to create a virtual environment to isolate your project dependencies, ensuring that packages installed for one project don't interfere with other projects. It combines the functionality of pip (Python's package installer) and virtualenv (a tool for creating isolated Python environments)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Question 1**\n",
    "\n",
    "* Install Pipenv\n",
    "* What's the version of pipenv you installed?\n",
    "* Use `--version` to find out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`Terminal`\n",
    "\n",
    "----\n",
    "```bash\n",
    "        marcos@marcos:~$ pip install pipenv\n",
    "        marcos@marcos:~$ pipenv --version\n",
    "        marcos@marcos:~$ pipenv, version 2023.10.3\n",
    "```\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Question 2**\n",
    "\n",
    "* Use Pipenv to install Scikit-Learn version 1.3.1\n",
    "* What's the first hash for scikit-learn you get in Pipfile.lock? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To install Python packages in an isolated virtual environment I first navigate to the specific project directory. After that, I create an empty folder and execute the package installation command.\n",
    "\n",
    "`Terminal`\n",
    "\n",
    "-----\n",
    "\n",
    "```bash\n",
    "        marcos@marcos:~$ cd /GitHub/ML-zoomcamp/05-deploy/Homework\n",
    "        marcos@marcos:~/GitHub/ML-zoomcamp/05-deploy/Homework$ mkdir Homework\n",
    "        marcos@marcos:~$ pipenv install Scikit-Learn==1.3.1\n",
    "```\n",
    "\n",
    "```bash\n",
    "        Output -------------\n",
    "        Updated Pipfile.lock (0e0fec5cb0e411bbb2c1c4f81b061609272a25d0c1f780d06dd30aff281bed02)\n",
    "        To activate this project's virtualenv, run pipenv shell.\n",
    "        Alternatively, run a command inside the virtualenv with pipenv run.\n",
    "```\n",
    "-----\n",
    "\n",
    "- `Pipfile`: list of libraries and version of Python used\n",
    "\n",
    "- `Pipfile.lock`: Contains the specific versions of the libraries that we used for the project.\n",
    "\n",
    "The hash value associated with the current `Pipfile.lock` serves a similar function to Git commit hashes.\n",
    "\n",
    "- Hash `pipfile.lock`: `0e0fec5cb0e411bbb2c1c4f81b061609272a25d0c1f780d06dd30aff281bed02`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Load Model with Pickle**\n",
    "\n",
    "Pickle allows for the serialization of Python objects, enabling you to save and load machine learning models. With Pickle, we can store a trained model into a binary file and later reload it to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Question 3**\n",
    "\n",
    "Let's use these models!\n",
    "\n",
    "* Write a script for loading these models with pickle\n",
    "* Score this client:\n",
    "\n",
    "```json\n",
    "{\"job\": \"retired\", \"duration\": 445, \"poutcome\": \"success\"}\n",
    "```\n",
    "\n",
    "What's the probability that this client will get a credit? \n",
    "\n",
    "* 0.162\n",
    "* 0.392\n",
    "* 0.652\n",
    "* **0.902**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of loading a pre-trained model and utilizing it to predict the probability of get credit for a single customer is described in the following diagram:\n",
    "\n",
    "<center><img src = \"figures/model_service.png\" width=\"700\" height=\"400\"/></center>\n",
    "\n",
    "First, let's create a simple Python script that loads the existing model and utilizes it to make a prediction for a single customer. This script is saved in the Homework/question3.py folder. Inside this Python file, we have:\n",
    "\n",
    "`question3.py`\n",
    "\n",
    "---\n",
    "```python\n",
    "        import pickle\n",
    "        import numpy as np\n",
    "        import os\n",
    "\n",
    "        # Preditiction for a single customer\n",
    "        def single_pred(customer, dv, model):\n",
    "            X = dv.transform([customer])\n",
    "            y_pred = model.predict_proba(X)[:, 1]\n",
    "            return y_pred[0]\n",
    "\n",
    "        # Paths\n",
    "        filepath_dv = 'dv.bin'\n",
    "        filepath_model = 'model1.bin'\n",
    "\n",
    "        # Load dictionary vectorizer\n",
    "        if os.path.exists(filepath_dv):\n",
    "            with open(filepath_dv, 'rb') as f_dv:\n",
    "                dv = pickle.load(f_dv)\n",
    "        else:\n",
    "            print(f\"File {filepath_dv} not found.\")\n",
    "\n",
    "        # Load model\n",
    "        if os.path.exists(filepath_model):\n",
    "            with open(filepath_model, 'rb') as f_model:\n",
    "                model = pickle.load(f_model)\n",
    "        else:\n",
    "            print(f\"File {filepath_model} not found.\")\n",
    "\n",
    "        customer = {\"job\": \"retired\", \"duration\": 445, \"poutcome\": \"success\"}\n",
    "        pred = single_pred(customer, dv, model)\n",
    "\n",
    "        print('prediction: %.3f' % pred)\n",
    "        if pred >= 0.5:\n",
    "            print('Get Credit: High')\n",
    "        else:\n",
    "            print('Get Credit: Low')\n",
    "```\n",
    "---\n",
    "\n",
    "\n",
    "With the script ready, let's activate the virtual environment and execute the script in the terminal, therefore isolating the required dependencies to run the script.\n",
    "\n",
    "`Terminal`\n",
    "\n",
    "------\n",
    "```bash\n",
    "        marcos@marcos:~/GitHub/ML-zoomcamp/05-deploy/Homework$ pipenv shell\n",
    "        Launching subshell in virtual environment...\n",
    "        marcos@marcos:~/GitHub/ML-zoomcamp/05-deploy/Homework$  . /home/marcos/.local/share/virtualenvs/Homework-zL5dlJ2M/bin/activate\n",
    "        marcos@marcos:~/GitHub/ML-zoomcamp/05-deploy/Homework$  python question3.py\n",
    "\n",
    "\n",
    "        $ prediction: 0.902\n",
    "        $ Get Credit: High\n",
    "```\n",
    "-------\n",
    "\n",
    "then we can exit the virtual environment with `exit`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Load Model in Web service with Flask**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Question 4**\n",
    "\n",
    "Now let's serve this model as a web service\n",
    "\n",
    "* Install Flask and gunicorn (or waitress, if you're on Windows)\n",
    "* Write Flask code for serving the model\n",
    "* Now score this client using `requests`:\n",
    "\n",
    "```python\n",
    "    url = \"YOUR_URL\"\n",
    "    customer = {\"job\": \"unknown\", \"duration\": 270, \"poutcome\": \"failure\"}\n",
    "    requests.post(url, json=customer).json()\n",
    "```\n",
    "What's the probability that this client will get a credit?\n",
    "\n",
    "* **0.140**\n",
    "* 0.440\n",
    "* 0.645\n",
    "* 0.845"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, let's create the Python script. This script is saved in the Homework/question4.py folder. Inside this Python file, we have:\n",
    "\n",
    "`question4.py`\n",
    "\n",
    "------\n",
    "```python\n",
    "        import pickle\n",
    "        import os\n",
    "        from flask import Flask, request, jsonify\n",
    "\n",
    "        # request: To get the content of a POST request\n",
    "        # jsonsify: To respond with JSON (dictionary)\n",
    "\n",
    "        # Preditiction for a single customer\n",
    "        def single_pred(customer, dv, model):\n",
    "            X = dv.transform([customer])\n",
    "            y_pred = model.predict_proba(X)[:, 1]\n",
    "            return y_pred[0]\n",
    "\n",
    "\n",
    "        # Paths\n",
    "        filepath_dv = 'dv.bin'\n",
    "        filepath_model = 'model1.bin'\n",
    "\n",
    "        # Load dictionary vectorizer\n",
    "        if os.path.exists(filepath_dv):\n",
    "            with open(filepath_dv, 'rb') as f_dv:\n",
    "                dv = pickle.load(f_dv)\n",
    "        else:\n",
    "            print(f\"File {filepath_dv} not found.\")\n",
    "\n",
    "        # Load model\n",
    "        if os.path.exists(filepath_model):\n",
    "            with open(filepath_model, 'rb') as f_model:\n",
    "                model = pickle.load(f_model)\n",
    "        else:\n",
    "            print(f\"File {filepath_model} not found.\")\n",
    "\n",
    "        app = Flask('churn')\n",
    "        # Registers the /predict route, and assigns it to the predict function\n",
    "        @app.route('/predict', methods=['POST'])\n",
    "        def predict():\n",
    "            customer =  request.get_json()\n",
    "            pred = single_pred(customer, dv, model)\n",
    "            result = {'Credit probability': float(pred)}\n",
    "            return jsonify(result)\n",
    "\n",
    "        if __name__ == '__main__':\n",
    "            #To test it, open the browser and type 'localhost:9696/predict'\n",
    "            app.run(debug=True, host='0.0.0.0', port=9696)\n",
    "```\n",
    "----\n",
    "\n",
    "To run the web service, we run the Python file. This starts the Flask web service, making it accessible at `http://127.0.0.1:9696.`\n",
    "\n",
    "\n",
    "`Terminal`\n",
    "\n",
    "----\n",
    "```bash\n",
    "        marcos@marcos:~/GitHub/ML_Zoomcamp/05Deploy/Homework$ python3 question4.py\n",
    "        * Running on all addresses (0.0.0.0)\n",
    "        * Running on http://127.0.0.1:9696\n",
    "        * Running on http://192.168.1.64:9696\n",
    "\n",
    "```\n",
    "----\n",
    "\n",
    "Once the web service is running, is possible to use HTTP POST requests to predict the credit probability for a given customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Credit probability': 0.13968947052356817}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://127.0.0.1:9696/predict\"\n",
    "customer = {\"job\": \"unknown\", \"duration\": 270, \"poutcome\": \"failure\"}\n",
    "requests.post(url, json = customer).json()\n",
    "\n",
    "# Output: {'Credit probability': 0.13968947052356817}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **5. Docker**\n",
    "\n",
    "Docker solves the problem with environment inconsistencies, by creating an isolated application called container, with Python dependencies, the operating system, and system libraries. This ensures uniform behavior across diverse operation systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src = \"figures/docker.png\" width=\"700\" height=\"300\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Question 5**\n",
    "\n",
    "- Base image: `svizor/zoomcamp-model:3.10.12-slim`. \n",
    "\n",
    "This image is based on `python:3.10.12-slim` and has a logistic regression model \n",
    "(a different one) as well a dictionary vectorizer inside. \n",
    "\n",
    "This is how the Dockerfile for this image looks like:\n",
    "\n",
    "`Dockerfile`\n",
    "\n",
    "----\n",
    "```docker \n",
    "        FROM python:3.10.12-slim\n",
    "        WORKDIR /app\n",
    "        COPY [\"model2.bin\", \"dv.bin\", \"./\"]\n",
    "```\n",
    "----\n",
    "\n",
    "The Dockerfile is a script containing commands that creates a snapshot of our application along with its dependencies, environment settings. To create a Docker image from the Dockerfile we run the command line  `sudo docker build -t custom-image-name .`. \n",
    "\n",
    "The image here was already built it and then pushed it to [`svizor/zoomcamp-model:3.10.12-slim`](https://hub.docker.com/r/svizor/zoomcamp-model).\n",
    "\n",
    "\n",
    "Download the base image `svizor/zoomcamp-model:3.10.12-slim` by using [docker pull](https://docs.docker.com/engine/reference/commandline/pull/) command.\n",
    "\n",
    "So what's the size of this base image?\n",
    "\n",
    "* 47 MB\n",
    "* **147 MB**\n",
    "* 374 MB\n",
    "* 574 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "`Terminal`\n",
    "\n",
    "----\n",
    "```bash\n",
    "    marcos@marcos:~$ sudo docker pull svizor/zoomcamp-model:3.10.12-slim\n",
    "    marcos@marcos:~$ sudo docker images\n",
    "    $ REPOSITORY              TAG            IMAGE ID       CREATED      SIZE\n",
    "    $ svizor/zoomcamp-model   3.10.12-slim   08266c8f0c4b   6 days ago   147MB\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Question 6**\n",
    "\n",
    "Now create your own Dockerfile based on the image we prepared.\n",
    "\n",
    "It should start like that:\n",
    "\n",
    "`Dockerfile`\n",
    "\n",
    "-----\n",
    "```docker\n",
    "    FROM svizor/zoomcamp-model:3.10.12-slim\n",
    "    # add rest of the commands\n",
    "```\n",
    "----\n",
    "\n",
    "Now complete it:\n",
    "\n",
    "* Install all the dependencies form the Pipenv file\n",
    "* Copy your Flask script\n",
    "* Run it with Gunicorn \n",
    "\n",
    "After that, you can build your docker image. Now Let's run your docker container!\n",
    "\n",
    "After running it, score this client once again:\n",
    "\n",
    "```python\n",
    "url = \"YOUR_URL\"\n",
    "client = {\"job\": \"retired\", \"duration\": 445, \"poutcome\": \"success\"}\n",
    "requests.post(url, json=client).json()\n",
    "```\n",
    "\n",
    "What's the probability that this client will get a credit now?\n",
    "\n",
    "* 0.168\n",
    "* 0.530\n",
    "* **0.730**\n",
    "* 0.968"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step is to include all the necessary Python packages that your Docker container will use. Let's update our Pipfile to includes Flask, Requests, Scikit-Learn, and Gunicorn.\n",
    "\n",
    "`Pipfile`\n",
    "\n",
    "----\n",
    "```bash\n",
    "    [[source]]\n",
    "    url = \"https://pypi.org/simple\"\n",
    "    verify_ssl = true\n",
    "    name = \"pypi\"\n",
    "\n",
    "    [packages]\n",
    "    flask = \"*\"\n",
    "    requests = \"*\"\n",
    "    scikit-learn = \"==1.3.1\"\n",
    "    gunicorn = \"*\"\n",
    "\n",
    "    [dev-packages]\n",
    "\n",
    "    [requires]\n",
    "    python_version = \"3.10\"\n",
    "```\n",
    "----\n",
    "\n",
    "The Dockerfile serves has a kind of template for building our Docker image. Setting up the Dockerfile:\n",
    "\n",
    "`Dockerfile`\n",
    "\n",
    "----\n",
    "```docker\n",
    "    # Start with the existing image as a base\n",
    "    FROM svizor/zoomcamp-model:3.10.12-slim\n",
    "\n",
    "    # Set environment variables\n",
    "    ENV PYTHONUNBUFFERED=TRUE\n",
    "\n",
    "    # Install pipenv\n",
    "    RUN pip --no-cache-dir install pipenv\n",
    "\n",
    "    # Set the working directory inside the container\n",
    "    WORKDIR /app\n",
    "\n",
    "    # Copy the Flask script, Pipenv files into the container\n",
    "    COPY [\"question6.py\", \"Pipfile\", \"Pipfile.lock\", \"./\"]\n",
    "\n",
    "    # Install Python dependencies and clean cache\n",
    "    RUN pipenv install --deploy --system && \\\n",
    "    rm -rf /root/.cache\n",
    "\n",
    "    # Port the app runs on\n",
    "    EXPOSE 9696\n",
    "\n",
    "    # Run Gunicorn when the container are started\n",
    "    ENTRYPOINT [\"gunicorn\", \"--bind\", \"0.0.0.0:9696\", \"question6:app\"]\n",
    "```\n",
    "----\n",
    "\n",
    "\n",
    "Once the Dockerfile is completed, we can build the base image. This is achieved using the command `sudo docker build -t custom-image-name . `. Here, the -t flag allows us to assign a custom tag name to the image. The final argument — represented by the dot — indicates that the Dockerfile resides in the current directory.\n",
    "\n",
    "After successfully building the image, it can be executed using the command `sudo docker run -p 9696:9696 custom-image-name`. In the terminal, we first update the `Pipfile.lock` to ensure it is synced with our Pipfile. Following that, we prepare the Docker image for deployment.\n",
    "\n",
    "\n",
    "`Terminal`\n",
    "\n",
    "-----\n",
    "\n",
    "```bash\n",
    "    marcos@marcos:~/GitHub/ML_Zoomcamp/05Deploy/Homework$ pipenv lock\n",
    "    marcos@marcos:~/GitHub/ML_Zoomcamp/05Deploy/Homework$ sudo docker build -t homework5 .\n",
    "    marcos@marcos:~/GitHub/ML_Zoomcamp/05Deploy/Homework$ sudo docker images\n",
    "    $ REPOSITORY              TAG            IMAGE ID       CREATED          SIZE\n",
    "    $ homework5               latest         fd36a47c9cc5   24 seconds ago   431MB\n",
    "    $ svizor/zoomcamp-model   3.10.12-slim   08266c8f0c4b   7 days ago       147MB\n",
    "\n",
    "\n",
    "\n",
    "    marcos@marcos:~/GitHub/ML_Zoomcamp/05Deploy/Homework$ sudo docker run -p 9696:9696 homework5\n",
    "    [2023-10-16 12:14:51 +0000] [1] [INFO] Starting gunicorn 21.2.0\n",
    "    [2023-10-16 12:14:51 +0000] [1] [INFO] Listening at: http://0.0.0.0:9696 (1)\n",
    "    [2023-10-16 12:14:51 +0000] [1] [INFO] Using worker: sync\n",
    "    [2023-10-16 12:14:51 +0000] [7] [INFO] Booting worker with pid: 7\n",
    "\n",
    "```\n",
    "------\n",
    "\n",
    "The Docker container will have the following directory structure:\n",
    "\n",
    "- `/` (Root directory)\n",
    "  - `usr/`\n",
    "    - `local/`\n",
    "      - `lib/`\n",
    "        - `python3.10/`\n",
    "          - `site-packages/` (Python packages)\n",
    "  - `app/` (Set as WORKDIR)\n",
    "    - `question6.py` \n",
    "    - `model2.bin` \n",
    "    - `dv.bin` \n",
    "    - `Pipfile` \n",
    "    - `Pipfile.lock` \n",
    "\n",
    "\n",
    "Once Flask is operational inside the Docker container, we can interact with it via HTTP POST requests to predict a customer's credit probability. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Credit probability': 0.726936946355423}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"http://127.0.0.1:9696/predict\"\n",
    "customer = {\"job\": \"retired\", \"duration\": 445, \"poutcome\": \"success\"}\n",
    "requests.post(url, json = customer).json()\n",
    "\n",
    "# {'Credit probability': 0.726936946355423}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
