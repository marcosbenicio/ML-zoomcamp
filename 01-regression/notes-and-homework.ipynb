{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Outline**\n",
    "\n",
    "- [**1. Exploratory Data Analysis (EDA)**](#1-exploratory-data-analysis-eda)\n",
    "- [**2. Data Splitting**](#2-data-splitting)\n",
    "- [**3. Linear Regression**](#3-linear-regression) \n",
    "- [**4. Ridge Regression ($L_2$)**](#4-ridge-regression-l2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Exploratory Data Analysis (EDA)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total houses (rows) : \n",
      " 20640 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('data/housing.csv')\n",
    "print(\"{} : \\n {} \\n\".format('total houses (rows)', len(df)))\n",
    "display(df.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>-121.97</td>\n",
       "      <td>37.64</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>6.0574</td>\n",
       "      <td>431000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>-121.99</td>\n",
       "      <td>37.61</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3666.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>4.6458</td>\n",
       "      <td>217000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>-121.97</td>\n",
       "      <td>37.57</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4342.0</td>\n",
       "      <td>783.0</td>\n",
       "      <td>2172.0</td>\n",
       "      <td>789.0</td>\n",
       "      <td>4.6146</td>\n",
       "      <td>247600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>-121.96</td>\n",
       "      <td>37.58</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3575.0</td>\n",
       "      <td>597.0</td>\n",
       "      <td>1777.0</td>\n",
       "      <td>559.0</td>\n",
       "      <td>5.7192</td>\n",
       "      <td>283500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>-121.98</td>\n",
       "      <td>37.58</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4126.0</td>\n",
       "      <td>1031.0</td>\n",
       "      <td>2079.0</td>\n",
       "      <td>975.0</td>\n",
       "      <td>3.6832</td>\n",
       "      <td>216900.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "701    -121.97     37.64                32.0       1283.0           194.0   \n",
       "830    -121.99     37.61                 9.0       3666.0           711.0   \n",
       "859    -121.97     37.57                21.0       4342.0           783.0   \n",
       "860    -121.96     37.58                15.0       3575.0           597.0   \n",
       "861    -121.98     37.58                20.0       4126.0          1031.0   \n",
       "\n",
       "     population  households  median_income  median_house_value  \n",
       "701       485.0       171.0         6.0574            431000.0  \n",
       "830      2341.0       703.0         4.6458            217000.0  \n",
       "859      2172.0       789.0         4.6146            247600.0  \n",
       "860      1777.0       559.0         5.7192            283500.0  \n",
       "861      2079.0       975.0         3.6832            216900.0  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "near_ocean= df['ocean_proximity'] == '<1H OCEAN'\n",
    "inland = df['ocean_proximity'] == 'INLAND'\n",
    "\n",
    "houses = df[near_ocean | inland]\n",
    "del houses['ocean_proximity']\n",
    "\n",
    "houses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Question 1**\n",
    "  \n",
    "There's one feature with missing values. What is it?\n",
    "\n",
    "* `total_rooms`\n",
    "* **`total_bedrooms`**\n",
    "* `population`\n",
    "* `households`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "longitude               0\n",
       "latitude                0\n",
       "housing_median_age      0\n",
       "total_rooms             0\n",
       "total_bedrooms        157\n",
       "population              0\n",
       "households              0\n",
       "median_income           0\n",
       "median_house_value      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing 157 values in total_bedrooms\n",
    "houses.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Question 2**\n",
    "  \n",
    "What's the median (50% percentile) for variable `'population'`?\n",
    "\n",
    "- 995\n",
    "- 1095\n",
    "- **1195**\n",
    "- 1295"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population median =  1195.0\n"
     ]
    }
   ],
   "source": [
    "print('Population median = ' , houses['population'].median())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Data Splitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Prepare and split the dataset\n",
    "\n",
    "- Shuffle the dataset (the filtered one you created above), use seed 42.\n",
    "- Split your data in train/val/test sets, with $60\\%/20\\%/20\\%$ distribution.\n",
    "- Apply the log transformation to the **median_house_value** variable using the `np.log1p()` function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Distributions of data\n",
    "n = len(houses)\n",
    "n_train = int(0.6*n)\n",
    "n_val = int(0.2*n)\n",
    "#n_test = int(0.2*n)\n",
    "\n",
    "# Shuffle data\n",
    "np.random.seed(42)\n",
    "idx = np.arange(n)\n",
    "np.random.shuffle(idx)\n",
    "houses_shuffled = houses.iloc[idx] \n",
    "\n",
    "# Split data\n",
    "X_train = houses_shuffled.iloc[:n_train].copy()\n",
    "X_val = houses_shuffled.iloc[n_train:n_train + n_val].copy()\n",
    "X_test = houses_shuffled.iloc[n_train+n_val:].copy()\n",
    "\n",
    "# Apply log transformation\n",
    "Y_train = np.log1p( X_train['median_house_value'] ).values\n",
    "Y_val = np.log1p( X_val['median_house_value'] ).values\n",
    "Y_test = np.log1p( X_test['median_house_value']).values \n",
    "\n",
    "# To avoid accidentally using the target variable\n",
    "del X_train['median_house_value']\n",
    "del X_val['median_house_value']\n",
    "del X_test['median_house_value']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Linear Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a hypothetical dataset with multiple features $X_{1},\\cdots, X_{d}$ and a target variable $Y$ as shown:\n",
    "\n",
    "$$\n",
    "\\left( \\begin{array}{c|cccc|c}\n",
    "~    &X_{0}&X_{1}&\\cdots & X_{d}  & Y\\\\\n",
    "\\hline\n",
    "x_{1} &1& x_{11}& \\cdots&x_{1d}&y_1 \\\\\n",
    "\\vdots&\\vdots&\\vdots&\\ddots&\\vdots&\\vdots\\\\\n",
    "x_{n}&1&x_{n1}&\\cdots&x_{nd}&y_n\n",
    "\\end{array} \\right).$$\n",
    "\n",
    "Here, each row vector $ \\mathbf{x}_i = (1, x_{i1}, \\ldots, x_{id}) $ represents an instance of the dataset with $ d+1 $ values. The first column, $ X_0 $, is the intercept term and is set to 1 for all instances. The dataset is separated in a feature matrix $\\mathbf{X}$ and a target vector $\\mathbf{Y}$:\n",
    "\n",
    "\n",
    "$$\\mathbf{X}=\n",
    "\\left( \\begin{array}{cccc}\n",
    " 1& x_{11}& \\cdots&x_{1d} \\\\\n",
    "\\vdots&\\vdots&\\ddots&\\vdots&\\\\\n",
    "1&x_{n1}&\\cdots&x_{nd}\n",
    "\\end{array} \\right) ~~~ \\text{and} ~~~ \n",
    "\n",
    "\\mathbf{Y} = \\left( \\begin{array}{c}\n",
    "y_1\\\\\n",
    "\\vdots\\\\\n",
    "y_n\n",
    "\\end{array} \\right)\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The linear regression model for multiple features $ X_1, \\ldots, X_d $ can be represented as:\n",
    "\n",
    "\n",
    "$$\\mathbf{\\hat{Y}} = \\mathbf{X}\\mathbf{w} $$\n",
    "\n",
    "Here, $\\mathbf{w} = (w_0, \\ldots, w_d)^T$ denotes the column vector of weights that the model seeks to learn for optimal regression. $\\mathbf{\\hat{Y}}$ represents the predicted values, and $\\mathbf{Y}$ stands for the true values (or target values). The error function commonly used is the sum of squared errors (SSE):\n",
    "\n",
    "$$\\text{SSE} = \\sum_{i}^{n} ||{\\epsilon}_i||^2 = \\mathbf{\\epsilon}\\mathbf{\\epsilon}^T$$\n",
    "\n",
    "where $\\mathbf{\\epsilon} = \\mathbf{\\hat{Y}} - \\mathbf{Y}$.\n",
    "\n",
    "Rearranging the error function gives:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{SSE} &= (\\mathbf{\\hat{Y}} - \\mathbf{Y})^T(\\mathbf{\\hat{Y}} - \\mathbf{Y})\\\\\n",
    "&=\\mathbf{Y}^T \\mathbf{Y}  - 2\\mathbf{Y}^T \\mathbf{\\hat{Y}} + \\mathbf{\\hat{Y}}^T \\mathbf{\\hat{Y}}\\\\\n",
    "&=\\mathbf{Y}^T \\mathbf{Y}  - 2\\mathbf{Y}^T  (\\mathbf{X}\\mathbf{w}) + ( \\mathbf{X}\\mathbf{w})^T ( \\mathbf{X}\\mathbf{w})\\\\\n",
    "&=\\mathbf{Y}^T \\mathbf{Y}  - 2 \\mathbf{w}^T (\\mathbf{X}^T\\mathbf{Y}) + \\mathbf{w}^T( \\mathbf{X}^T\\mathbf{X}) \\mathbf{w}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The goal is to minimize this error to optimize the ideal weights. Instead of using gradient descent, we take the derivative of the SSE with respect to the weights, set it equal to zero, and find a local minimum of the SSE function. This leads to the following optimal weights for the optimization problem:\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial (\\text{SSE})}{\\partial \\mathbf{w}} & = -2\\mathbf{X}^T\\mathbf{Y} + (\\mathbf{X}^T\\mathbf{X})\\mathbf{w} + \\mathbf{w}^T(\\mathbf{X}^T\\mathbf{X})\\\\\n",
    "& = -2\\mathbf{X}^T\\mathbf{Y} + 2(\\mathbf{X}^T\\mathbf{X})\\mathbf{w} = 0\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Solving for the optimal weights, we get the following analytical solution:\n",
    "\n",
    "$$\\mathbf{w} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}$$\n",
    "\n",
    "In summary, for a given dataset with multiple features, we can represent the linear regression model as a product of weights and input features. The objective is to minimize the sum of squared errors (SSE) to find the optimal weights for the model. By taking the derivative of the SSE with respect to the weights and setting it to zero, we can determine the optimal weights for the optimization problem using the above equation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Question 3**\n",
    "\n",
    "* We need to deal with missing values for the column from Q1.\n",
    "* We have two options: fill it with 0 or with the mean of this variable.\n",
    "* Try both options. For each, train a linear regression model without regularization using the code from the lessons.\n",
    "* For computing the mean, use the training only!\n",
    "* Use the validation dataset to evaluate the models and compare the RMSE of each option.\n",
    "* Round the RMSE scores to 2 decimal digits using `round(score, 2)`\n",
    "\n",
    "Which option gives better RMSE?\n",
    "\n",
    "- With 0\n",
    "- With mean\n",
    "- **Both are equally good**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling missing values with zeros and mean\n",
    "def handle_nan(df, feature, fillnan_with):\n",
    "    df_copy = df.copy()\n",
    "    if fillnan_with == 'mean':\n",
    "        df_copy[feature].fillna(value = df_copy[feature].mean(), inplace=True)\n",
    "    elif fillnan_with == 'zero':\n",
    "        df_copy[feature].fillna(value = 0, inplace=True)\n",
    "        \n",
    "    return df_copy.values\n",
    "\n",
    "# Root mean squared error\n",
    "def rmse(y, y_pred):\n",
    "    error = y_pred - y\n",
    "    mse = (error ** 2).mean()\n",
    "    rmse = np.sqrt(mse)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression(X, y):\n",
    "    # adding ones in the dataset X\n",
    "    X_0 = np.ones(X.shape[0])\n",
    "    X = np.column_stack([X_0, X])\n",
    "\n",
    "    XTX = X.T.dot(X)\n",
    "    XTX_inverse = np.linalg.inv(XTX)\n",
    "    w = XTX_inverse.dot(X.T).dot(y)\n",
    "\n",
    "    Y_pred = X.dot(w)\n",
    "    return Y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for train set with zeros:  0.34\n",
      "RMSE for train set with mean:  0.34\n",
      "\n",
      "\n",
      "RMSE for validation set with zeros:  0.34\n",
      "RMSE for validation set with mean:  0.34\n"
     ]
    }
   ],
   "source": [
    "# filling missing values\n",
    "X_train_zeros = handle_nan(X_train, 'total_bedrooms', 'zero')\n",
    "X_val_zeros = handle_nan(X_val, 'total_bedrooms', 'zero')\n",
    "\n",
    "X_train_mean = handle_nan(X_train, 'total_bedrooms', 'mean')\n",
    "X_val_mean = handle_nan(X_val, 'total_bedrooms', 'mean')\n",
    "\n",
    "# For training set\n",
    "Y_pred = linear_regression(X_train_zeros, Y_train)\n",
    "rmse_train_zeros = rmse(Y_train, Y_pred)\n",
    "print('RMSE for train set with zeros: ',round(rmse_train_zeros, 2) )\n",
    "\n",
    "Y_pred = linear_regression(X_train_mean, Y_train)\n",
    "rmse_train_mean= rmse(Y_train, Y_pred)\n",
    "print('RMSE for train set with mean: ',round(rmse_train_mean, 2) )\n",
    "\n",
    "print('\\n')\n",
    "# For validation set\n",
    "Y_pred = linear_regression(X_val_zeros, Y_val)\n",
    "rmse_val_zeros = rmse(Y_val, Y_pred)\n",
    "print('RMSE for validation set with zeros: ', round(rmse_train_mean, 2) )\n",
    "\n",
    "Y_pred = linear_regression(X_val_mean, Y_val)\n",
    "rmse_val_mean = rmse(Y_val, Y_pred)\n",
    "print('RMSE for validation set with mean: ',round(rmse_train_mean, 2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **4. Ridge Regression ($L_2$)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If two or more columns of a matrix are not orthogonal to each other (i.e., they are correlated), it implies that the matrix is not invertible (singular matrix). Consequently, the optimal weights equation:\n",
    "\n",
    "$$\\mathbf{w} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}$$\n",
    "\n",
    "becomes problematic, as the inverse matrix $(\\mathbf{X}^T\\mathbf{X})$ is either hard to compute accurately or non-existent. This can result in large or unstable estimates of the regression coefficients, which can lead to poor model performance.\n",
    "\n",
    "Regularization aims to ensure the existence of the inverse by forcing the matrix to be invertible, controlling the weights of the model so that they behave correctly and do not become too large.\n",
    "\n",
    "Instead of simple minimizing the squared residual error $||\\mathbf{Y} - \\mathbf{\\hat{Y}}||^2$, we add a regularization term involving the squared norm of the weights vector $|| \\mathbf{w} ||^2$:\n",
    "\n",
    "$$L(\\mathbf{w}) = ||\\mathbf{Y} - \\mathbf{\\hat{Y}}||^2 + \\alpha || \\mathbf{w} ||^2$$\n",
    "\n",
    "The goal is to minimize $L(\\mathbf{w})$. To achieve this, we take the derivative of $L(\\mathbf{w})$ with respect to the weights, set it equal to zero, and find a local minimum of the function. This results in the following optimal weights:\n",
    "\n",
    "$$\\frac{dL(\\mathbf{w})}{d\\mathbf{w}} = -2\\mathbf{X}^T\\mathbf{Y} + 2(\\mathbf{X}^T\\mathbf{X})\\mathbf{w} +2 \\alpha \\mathbf{w}= 0$$\n",
    "\n",
    "therefore, the optimal solution is\n",
    "\n",
    "$$\\mathbf{w} = (\\mathbf{X}^T\\mathbf{X}+ \\alpha \\mathbf{I})^{-1}\\mathbf{X}^T\\mathbf{Y}$$\n",
    "\n",
    "where $\\mathbf{I}$ is the identity matrix. The matrix $(\\mathbf{X}^T\\mathbf{X}+ \\alpha \\mathbf{I})$ is always invertible for $\\alpha > 0$. \n",
    "\n",
    "The reason behind this is that $\\mathbf{X}^T\\mathbf{X}$ is always symmetric and positive semi-definite, meaning all its eigenvalues are non-negative. However, this does not guarantee invertibility, as eigenvalues can still be zero, resulting in a singular matrix.\n",
    "\n",
    "When adding the two matrices, $(\\mathbf{X}^T\\mathbf{X} + \\alpha \\mathbf{I})$, the resulting matrix's eigenvalues are the sums of the corresponding eigenvalues of the original matrices. Since the eigenvalues of $\\mathbf{X}^T\\mathbf{X}$ are non-negative and those of $\\alpha \\mathbf{I}$ are positive, the eigenvalues of $(\\mathbf{X}^T\\mathbf{X} + \\alpha \\mathbf{I})$ are strictly positive. A symmetric matrix with strictly positive eigenvalues is positive definite, which are always invertible as none of their eigenvalues are equal to zero. Consequently, the matrix $(\\mathbf{X}^T\\mathbf{X} + \\alpha \\mathbf{I})$ is always invertible for $\\alpha > 0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ridge_regression(X, y, r = 0.0):\n",
    "    # adding ones in the dataset X\n",
    "    X_0 = np.ones(X.shape[0])\n",
    "    X = np.column_stack([X_0, X])\n",
    "\n",
    "    XTX = X.T.dot(X)\n",
    "    # add regularization term rI\n",
    "    I = np.eye(XTX.shape[0])\n",
    "    XTX_inverse = np.linalg.inv(XTX + r*I)\n",
    "    w = XTX_inverse.dot(X.T).dot(y)\n",
    "\n",
    "    Y_pred = X.dot(w)\n",
    "    return Y_pred, w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Question 4**\n",
    "\n",
    "* Now let's train a regularized linear regression.\n",
    "* For this question, fill the NAs with 0. \n",
    "* Try different values of `r` from this list: `[0, 0.000001, 0.0001, 0.001, 0.01, 0.1, 1, 5, 10]`.\n",
    "* Use RMSE to evaluate the model on the validation dataset.\n",
    "* Round the RMSE scores to 2 decimal digits.\n",
    "\n",
    "Which `r` gives the best RMSE? If there are multiple options, select the smallest `r`.\n",
    "\n",
    "- **0**\n",
    "- 0.000001\n",
    "- 0.001\n",
    "- 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0 0.34000\n",
      " 1e-06 0.34000\n",
      "0.0001 0.34000\n",
      " 0.001 0.34000\n",
      "  0.01 0.34003\n",
      "   0.1 0.34128\n",
      "     1 0.34616\n",
      "     5 0.34770\n",
      "    10 0.34794\n"
     ]
    }
   ],
   "source": [
    "# filling missing values with zeros\n",
    "X_train = handle_nan(X_train, 'total_bedrooms', 'zero')\n",
    "X_val = handle_nan(X_val, 'total_bedrooms', 'zero')\n",
    "\n",
    "\n",
    "for r in [0, 0.000001, 0.0001, 0.001, 0.01, 0.1, 1, 5, 10]:\n",
    "    Y_pred, _ = ridge_regression(X_val, Y_val, r=r)\n",
    "    rmse_val = round( rmse(Y_val, Y_pred), 5)\n",
    "    print('%06s %0.5f' % (r, rmse_val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If multiple options yield similar results, it is common practice to select the smallest regularization term. In this case, $r=0$, suggesting that regularization is not necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Question 5**\n",
    "\n",
    "- We used seed $42$ for splitting the data. Let's find out how selecting the seed influences our score.\n",
    "- Try different seed values: $[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]$.\n",
    "- For each seed, do the train/validation/test split with $60\\%/20\\%/20\\%$ distribution.\n",
    "- Fill the missing values with $0$ and train a model without regularization.\n",
    "- For each seed, evaluate the model on the validation dataset and collect the RMSE scores.\n",
    "- What's the standard deviation of all the scores? To compute the standard deviation, use np.std.\n",
    "- Round the result to $3$ decimal digits (`round(std, 3)`)\n",
    "\n",
    "\n",
    "What's the value of std?\n",
    "\n",
    "- 0.5\n",
    "- 0.05\n",
    "- **0.005**\n",
    "- 0.0005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(df, target_column, train_size = 0.6, \n",
    "               val_size = 0.2, seed = 42, log_transform = True):\n",
    "    \n",
    "    if train_size + val_size >= 1.0:\n",
    "        raise ValueError(\"Value larger then 1\")\n",
    "    \n",
    "    n = len(df)\n",
    "    n_train = int(train_size*n)\n",
    "    n_val = int(val_size*n)\n",
    "    \n",
    "    # Shuffle data\n",
    "    np.random.seed(seed)\n",
    "    idx = np.arange(n)\n",
    "    np.random.shuffle(idx)\n",
    "    df_shuffled = df.iloc[idx]\n",
    "\n",
    "    # Split data\n",
    "    X_train = df_shuffled.iloc[:n_train].copy()\n",
    "    X_val = df_shuffled.iloc[n_train:n_train + n_val].copy()\n",
    "    X_test = df_shuffled.iloc[n_train + n_val:].copy()\n",
    "\n",
    "    if log_transform:\n",
    "        Y_train = np.log1p(X_train[target_column]).values\n",
    "        Y_val = np.log1p(X_val[target_column]).values\n",
    "        Y_test = np.log1p(X_test[target_column]).values\n",
    "    else:\n",
    "        Y_train = X_train[target_column].values\n",
    "        Y_val = X_val[target_column].values\n",
    "        Y_test = X_test[target_column].values\n",
    "\n",
    "    del X_train[target_column]\n",
    "    del X_val[target_column]\n",
    "    del X_test[target_column]\n",
    "\n",
    "    # Fill missing values with zeros\n",
    "    X_train = handle_nan(X_train, 'total_bedrooms', 'zero')\n",
    "    X_val = handle_nan(X_val, 'total_bedrooms', 'zero')\n",
    "    X_test = handle_nan(X_test, 'total_bedrooms', 'zero')\n",
    "\n",
    "    X = {'train':X_train, 'val':X_val, 'test':X_test}\n",
    "    Y = {'train': Y_train,'val':Y_val,'test': Y_test}\n",
    "\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>-121.97</td>\n",
       "      <td>37.64</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>485.0</td>\n",
       "      <td>171.0</td>\n",
       "      <td>6.0574</td>\n",
       "      <td>431000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>830</th>\n",
       "      <td>-121.99</td>\n",
       "      <td>37.61</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3666.0</td>\n",
       "      <td>711.0</td>\n",
       "      <td>2341.0</td>\n",
       "      <td>703.0</td>\n",
       "      <td>4.6458</td>\n",
       "      <td>217000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "701    -121.97     37.64                32.0       1283.0           194.0   \n",
       "830    -121.99     37.61                 9.0       3666.0           711.0   \n",
       "\n",
       "     population  households  median_income  median_house_value  \n",
       "701       485.0       171.0         6.0574            431000.0  \n",
       "830      2341.0       703.0         4.6458            217000.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0 0.337\n",
      "         1 0.337\n",
      "         2 0.337\n",
      "         3 0.331\n",
      "         4 0.337\n",
      "         5 0.342\n",
      "         6 0.334\n",
      "         7 0.344\n",
      "         8 0.35\n",
      "         9 0.334\n",
      "Std = 0.005\n"
     ]
    }
   ],
   "source": [
    "display(houses.head(2))\n",
    "\n",
    "seeds = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "errors = []\n",
    "for seed in seeds:\n",
    "    X,Y = split_data(df = houses, target_column= 'median_house_value', seed = seed)\n",
    "    Y_pred = linear_regression(X['val'], Y['val'])\n",
    "    error = rmse(Y['val'], Y_pred)\n",
    "\n",
    "    print('%10s' %seed, round( error, 3) )\n",
    "    errors.append( error )   \n",
    "\n",
    "print('Std =', round(np.std(errors), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard deviation shows how different the values are. If it's low, then all values are approximately the same. If it's high, the values are different. If standard deviation of scores is low, then our model is stable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Question 6**\n",
    "\n",
    "- Split the dataset like previously, use seed $9$.\n",
    "- Combine train and validation datasets.\n",
    "- Fill the missing values with $0$ and train a model with $r=0.001$.\n",
    "\n",
    "\n",
    "What's the RMSE on the test dataset?\n",
    "\n",
    "- 0.13\n",
    "- 0.23\n",
    "- **0.33**\n",
    "- 0.43\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on test set =  0.33\n"
     ]
    }
   ],
   "source": [
    "# Split data and fill missing values with zeros\n",
    "X,Y = split_data(df = houses, target_column= 'median_house_value', seed = 9)\n",
    "\n",
    "# Combine train and validation\n",
    "X_train = np.concatenate([ X['train'], X['val']])\n",
    "Y_train = np.concatenate([ Y['train'], Y['val']])\n",
    "\n",
    "# Train model on train and validation and use in test set\n",
    "_, w = ridge_regression(X_train, Y_train, r = 0.001)\n",
    "\n",
    "# Regression with the trained weights\n",
    "Y_pred = w[0] + X['test'].dot(w[1:])\n",
    "\n",
    "\n",
    "print('RMSE on test set = ', round( rmse(Y['test'], Y_pred), 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
